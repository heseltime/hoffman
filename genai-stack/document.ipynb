{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import fitz  # PyMuPDF\n",
    "import requests\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load env\n",
    "load_dotenv(\".env\")\n",
    "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\")\n",
    "LLM_NAME = os.getenv(\"LLM\")\n",
    "\n",
    "MAX_RETRIES_LLM_LOOP_DEFAULT = int(os.getenv(\"MAX_RETRIES_LLM_LOOP_DEFAULT\", \"5\"))\n",
    "\n",
    "# Optional hyperparameters\n",
    "LIMIT_LINES = os.getenv(\"LIMIT_LINES\", \"False\").lower() == \"true\"\n",
    "LINES_LIMIT = int(os.getenv(\"LINES_LIMIT\", \"1000\"))\n",
    "\n",
    "logger.info(\"ü§ñ Using LLM model: %s\", LLM_NAME)\n",
    "logger.info(\"üîß LIMIT_LINES=%s, LINES_LIMIT=%d\", LIMIT_LINES, LINES_LIMIT)\n",
    "\n",
    "# --- QPDF decompression ---\n",
    "def uncompress_pdf(input_pdf_path: Path, output_pdf_path: Path):\n",
    "    logger.info(\"üîì Uncompressing: %s\", input_pdf_path)\n",
    "    subprocess.run([\n",
    "        \"qpdf\", \"--qdf\", \"--object-streams=disable\",\n",
    "        str(input_pdf_path), str(output_pdf_path)\n",
    "    ], check=True)\n",
    "    logger.info(\"üíæ Saved uncompressed to: %s\", output_pdf_path)\n",
    "\n",
    "# --- Extract content streams from PDF ---\n",
    "def extract_pdf_content_streams(path: str, limit_lines=False, max_lines=1000) -> list[str]:\n",
    "    logger.info(\"üìÇ Extracting from PDF: %s\", path)\n",
    "    doc = fitz.open(path)\n",
    "    streams = []\n",
    "    for i, page in enumerate(doc):\n",
    "        xrefs = page.get_contents()\n",
    "        if not xrefs:\n",
    "            logger.warning(\"‚ö†Ô∏è No content stream on page %d\", i + 1)\n",
    "            streams.append(\"% No content\")\n",
    "            continue\n",
    "        stream = b\"\".join([doc.xref_stream(x) for x in xrefs])\n",
    "        try:\n",
    "            decoded = stream.decode(\"utf-8\", errors=\"ignore\")\n",
    "        except Exception as e:\n",
    "            logger.warning(\"‚ùó Decode error: %s\", e)\n",
    "            decoded = \"% Decode error\"\n",
    "        if limit_lines:\n",
    "            decoded = \"\\n\".join(decoded.splitlines()[:max_lines])\n",
    "        streams.append(decoded)\n",
    "    doc.close()\n",
    "    logger.info(\"‚úÖ Extracted %d stream(s)\", len(streams))\n",
    "    return streams\n",
    "\n",
    "\n",
    "# --- Build prompt using examples and target streams ---\n",
    "def build_prompt_with_examples(example_pairs, target_streams, limit_lines=False, max_lines=1000):\n",
    "    header = [\n",
    "        \"You are a low-level PDF code generator.\",\n",
    "        \"Given raw PDF page content streams (e.g., BT/ET text drawing blocks), your job is to rewrite each stream for accessibility.\",\n",
    "        \"Only return the improved PDF stream. Do not explain or comment.\",\n",
    "        \"Do not interpret the data. Do not describe the content. Do not wrap in markdown or text blocks.\",\n",
    "        \"Each input stream will be followed by your output stream.\",\n",
    "        \"Here are some examples of non-barrier-free PDF source code, and its barrier-free counterpart, respectively:\"\n",
    "    ]\n",
    "    prompt = \"\\n\".join(header)\n",
    "    for i, (na, a) in enumerate(example_pairs):\n",
    "        input_block = \"\\n\".join(na.strip().splitlines()[:max_lines]) if limit_lines else na.strip()\n",
    "        output_block = \"\\n\".join(a.strip().splitlines()[:max_lines]) if limit_lines else a.strip()\n",
    "        prompt += f\"\\n\\n% Example {i+1}:\\nInput:\\n{input_block}\\nOutput:\\n{output_block}\"\n",
    "    prompt += \"\\n\\nNow improve the following:\"\n",
    "    for stream in target_streams:\n",
    "        body = \"\\n\".join(stream.strip().splitlines()[:max_lines]) if limit_lines else stream.strip()\n",
    "        prompt += f\"\\n\\n{body}\"\n",
    "    return prompt\n",
    "\n",
    "# --- Call LLM via POST ---\n",
    "def call_llm_generate_streams(prompt: str, model: str, base_url: str, retries: int = 2) -> list[str]:\n",
    "    logger.info(\"üöÄ Calling LLM model '%s' at %s\", model, base_url)\n",
    "    for attempt in range(1, retries + 1):\n",
    "        logger.info(\"üß† LLM call attempt %d/%d\", attempt, retries)\n",
    "        try:\n",
    "            r = requests.post(\n",
    "                f\"{base_url}/api/generate\",\n",
    "                json={\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "        except Exception as e:\n",
    "            logger.error(\"üö® LLM request failed: %s\", e)\n",
    "            continue\n",
    "\n",
    "        response = r.json().get(\"response\", \"\")\n",
    "        logger.info(\"üí¨ LLM response (first 500 chars): %s\", response[:500].replace(\"\\n\", \"\\\\n\"))\n",
    "\n",
    "        if \"```\" in response:\n",
    "            logger.warning(\"‚ö†Ô∏è Code block markers found in response ‚Äî skipping.\")\n",
    "            continue\n",
    "\n",
    "        parts = [blk.strip() + \"\\nendstream\" for blk in response.split(\"endstream\") if blk.strip()]\n",
    "        if not parts:\n",
    "            logger.warning(\"‚ö†Ô∏è No usable stream blocks found.\")\n",
    "            continue\n",
    "\n",
    "        logger.info(\"‚úÖ Parsed %d stream blocks\", len(parts))\n",
    "        return parts\n",
    "\n",
    "    raise RuntimeError(\"LLM failed to return valid stream content after retries.\")\n",
    "\n",
    "# --- Write PDF with fpdf ---\n",
    "def build_full_pdf_from_streams(streams: list[str], output_path: str, limit_lines=False, max_lines=1000):\n",
    "    pdf = FPDF()\n",
    "    pdf.set_font(\"Helvetica\", size=12)\n",
    "    for stream in streams:\n",
    "        pdf.add_page()\n",
    "        lines = stream.splitlines()\n",
    "        if limit_lines:\n",
    "            lines = lines[:max_lines]\n",
    "        for line in lines:\n",
    "            pdf.cell(0, 10, line[:100], ln=True)\n",
    "    pdf.output(output_path)\n",
    "    logger.info(\"üìÑ PDF written to: %s\", output_path)\n",
    "\n",
    "# --- Collect example PDF pairs ---\n",
    "def collect_example_pairs(input_dir: Path, max_pages=1, limit_lines=False, max_lines=1000):\n",
    "    pairs = []\n",
    "    for bf_path in input_dir.glob(\"* bf.pdf\"):\n",
    "        orig_path = input_dir / bf_path.name.replace(\" bf.pdf\", \".pdf\")\n",
    "        if not orig_path.exists():\n",
    "            continue\n",
    "        logger.info(\"üìö Pair: %s + %s\", orig_path.name, bf_path.name)\n",
    "\n",
    "        tmp_dir = Path(\"/tmp/pdf_examples\")\n",
    "        tmp_dir.mkdir(parents=True, exist_ok=True)\n",
    "        orig_u = tmp_dir / f\"{orig_path.stem}_u.pdf\"\n",
    "        bf_u = tmp_dir / f\"{bf_path.stem}_u.pdf\"\n",
    "        uncompress_pdf(orig_path, orig_u)\n",
    "        uncompress_pdf(bf_path, bf_u)\n",
    "\n",
    "        orig_streams = extract_pdf_content_streams(str(orig_u), limit_lines=limit_lines, max_lines=max_lines)[:max_pages]\n",
    "        bf_streams = extract_pdf_content_streams(str(bf_u), limit_lines=limit_lines, max_lines=max_lines)[:max_pages]\n",
    "        pairs.extend(zip(orig_streams, bf_streams))\n",
    "\n",
    "    logger.info(\"üßæ Loaded %d example stream pairs\", len(pairs))\n",
    "    return pairs\n",
    "\n",
    "# --- Process a single PDF with prompt and output ---\n",
    "def process_pdf_for_accessibility(input_pdf_path, example_pairs=None, output_dir=\"/tmp\", retries=2):\n",
    "    input_path = Path(input_pdf_path)\n",
    "    uncompressed_path = Path(output_dir) / f\"{input_path.stem}_uncompressed{input_path.suffix}\"\n",
    "    uncompress_pdf(input_path, uncompressed_path)\n",
    "\n",
    "    content_streams = extract_pdf_content_streams(str(uncompressed_path), limit_lines=LIMIT_LINES, max_lines=LINES_LIMIT)\n",
    "    prompt = build_prompt_with_examples(example_pairs or [], content_streams, limit_lines=LIMIT_LINES, max_lines=LINES_LIMIT)\n",
    "\n",
    "    prompt_file = Path(output_dir) / f\"{input_path.stem}.prompt.txt\"\n",
    "    prompt_file.write_text(prompt, encoding=\"utf-8\")\n",
    "\n",
    "    improved_streams = call_llm_generate_streams(prompt, model=LLM_NAME, base_url=OLLAMA_BASE_URL, retries=retries)\n",
    "\n",
    "    if LIMIT_LINES:\n",
    "        response_text = \"\\n\\n\".join([\"\\n\".join(s.splitlines()[:LINES_LIMIT]) for s in improved_streams])\n",
    "    else:\n",
    "        response_text = \"\\n\\n\".join(improved_streams)\n",
    "    response_file = Path(output_dir) / f\"{input_path.stem}.response.txt\"\n",
    "    response_file.write_text(response_text, encoding=\"utf-8\")\n",
    "\n",
    "    output_filename = f\"{input_path.stem} bf{input_path.suffix}\"\n",
    "    output_path = Path(output_dir) / output_filename\n",
    "    build_full_pdf_from_streams(improved_streams, str(output_path), limit_lines=LIMIT_LINES, max_lines=LINES_LIMIT)\n",
    "\n",
    "    return str(output_path)\n",
    "\n",
    "# --- Batch directory runner ---\n",
    "def process_pdf_directory(input_dir, output_dir, example_dir, retries=2):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    input_dir = Path(input_dir)\n",
    "    example_dir = Path(example_dir)\n",
    "\n",
    "    example_pairs = collect_example_pairs(example_dir, limit_lines=LIMIT_LINES, max_lines=LINES_LIMIT)\n",
    "\n",
    "    for file in input_dir.glob(\"*.pdf\"):\n",
    "        if \" bf.pdf\" in file.name:\n",
    "            continue\n",
    "        if (input_dir / f\"{file.stem} bf.pdf\").exists():\n",
    "            continue\n",
    "        try:\n",
    "            output_path = process_pdf_for_accessibility(\n",
    "                str(file), example_pairs=example_pairs, output_dir=output_dir, retries=retries\n",
    "            )\n",
    "            print(f\"‚úÖ Processed: {file.name} ‚Üí {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed: {file.name} ‚Äî {e}\")\n",
    "\n",
    "# --- Entry point ---\n",
    "INPUT_DIR = \"./ipynb-input\"\n",
    "OUTPUT_DIR = \"./ipynb-output\"\n",
    "EXAMPLE_DIR = \"./ipynb-examples\"\n",
    "\n",
    "process_pdf_directory(INPUT_DIR, OUTPUT_DIR, EXAMPLE_DIR, MAX_RETRIES_LLM_LOOP_DEFAULT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
